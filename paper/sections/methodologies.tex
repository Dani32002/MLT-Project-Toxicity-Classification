\section{Machine learning Methods}
This section describes the classification methods used in this study. Each represents a different approach within supervised learning.

\input{sections/methodologies/randomforest.tex}

\input{sections/methodologies/decisiontree.tex}

\input{sections/methodologies/logisticregression.tex}

\input{sections/methodologies/adaboost.tex}

\input{sections/methodologies/naivebayes.tex}

\input{sections/methodologies/supportvectormachine.tex}

\section{Deep Learning Methods}
Deep learning is a subset of machine learning that uses artificial neural networks with many layers to automatically learn complex patterns from large amounts of data.

\subsection{Artificial Neural Networks (ANN)}
\subsubsection{Definition}
Artificial Neural Networks are computational models inspired by the human brain, composed of layers of interconnected nodes (neurons). Each neuron receives inputs, processes them with a weight and bias, and applies an activation function to produce an output.

\subsection{Convolutional Neural Networks (CNN)}
\subsubsection{Definition}
Convolutional Neural Networks are specialized neural networks primarily used for image processing tasks. They use convolutional layers to automatically extract spatial features from images, followed by pooling and fully connected layers for classification.

\subsection{Recurrent Neural Networks (RNN)}
\subsubsection{Definition}
Recurrent Neural Networks are designed to recognize patterns in sequences of data by using loops in the network to maintain information across time steps. They are commonly used in natural language processing and time-series prediction.

\subsection{Long Short-Term Memory (LSTM)}
\subsubsection{Definition}
Long Short-Term Memory networks are a type of RNN that can learn long-term dependencies using a special architecture that controls the flow of information. They are effective in handling the vanishing gradient problem during training.

\subsection{Autoencoders}
\subsubsection{Definition}
Autoencoders are unsupervised neural networks that learn efficient codings of data. They consist of an encoder that compresses the data and a decoder that reconstructs it. They are used for tasks like dimensionality reduction and anomaly detection.

\subsection{Generative Adversarial Networks (GAN)}
\subsubsection{Definition}
Generative Adversarial Networks consist of two neural networks—the generator and the discriminator—that compete against each other. The generator creates synthetic data, while the discriminator evaluates them, leading to the generation of highly realistic data.
